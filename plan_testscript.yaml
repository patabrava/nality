Implement plan in phases by following the PLAN\_TESTSCRIPT guidelines: break your roadmap into clear slices, validate each slice with real-environment scripts or manual checks, drive tests from concrete examples, and bake in observability—then only move on when a slice is proven sound. For larger projects, you can optionally collect passing tests into a regression suite or automate execution, but for small scopes simple scripts or manual validation are sufficient.

PLAN_TESTSCRIPT
```yaml
---
plan_testscript_guidelines:
  - principle: "Phase-Based Validation"
    description: >
      Define discrete development phases (e.g. “Data layer,” “API endpoints,”
      “UI components,” “Integration”). For each phase, list exactly what must
      be delivered and what must be tested before proceeding.

  - principle: "Real-Environment Validation"
    description: >
      For medium-to-large projects, write end-to-end scripts or functions
      that exercise each feature in its actual environment (browser, server,
      or full stack). For small projects or prototypes, perform equivalent
      manual checks and document them.

  - principle: "Example-Driven Specs"
    description: >
      Base every test on concrete input/output examples. Capture normal flows,
      edge cases, and error conditions. Small projects may embed these checks
      inline; larger efforts should separate them into test files or suites.

  - principle: "Observability & Debugging"
    description: >
      Ensure each test failure emits enough context—structured logs,
      stack traces, screenshots, or network dumps—to pinpoint root causes
      quickly.

  # Optional, for larger or long-lived projects:
  - principle: "Regression & Automation"
    description: >
      After a phase’s tests pass, add them to a collective regression suite.
      Integrate that suite into your CI/CD or build process so tests run
      automatically on code changes.
---
```
END_PLAN_TESTSCRIPT
